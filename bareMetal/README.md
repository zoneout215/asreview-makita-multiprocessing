# Multprocessing the ARFI Simulation study with GNU parallel

## Description

This project does the parallelisation of ARFI Makita Template using GNU parallel package for bash.  
The implementation based on GNU is suitable for other Makta templates as well.
<h6> This project was rendered with ASReview-Makita version 0.6.3.
This project was rendered from the Makita-ARFI template.

See [asreview/asreview-makita#templates](https://github.com/asreview/asreview-makita#templates) for template rules and formats. The template is described as: ARFI 'All Relevant, Fixed Irrelevant'.

## Data

The performance on the following datasets is evaluated:

- data/van_de_Schoot_2018.csv

## Run simulation

To parallelize your `jobs.sh` file, first, we need to split it into blocks that can be parallelized.  
The `split-file.py` is inherited from and inspired by the Kubernetes implementation,  
and is was written by [Abel Siquera](https://github.com/abelsiqueira). 

### Steps:

1\. Run `split-file.py` script to separate `jobs.sh` file. 
```python
python scripts/split-file.py jobs.sh
```

2\. Then start with a non-parallelised run, specifying 1 as the number of CPUs.

```bash
bash parallel_run.sh 1
```
3\. The script will output the running time, collect it and store it. In our case time mesurements from the conducted analysis are stored in the parent directory of this repositrory in `data/experiment_resutls.csv`.
> Note
> If you want to reproduce the results of the study with max precision, do not run any
> computations or processes on your machine, as it will take CPU resources from the simulations run
> and will result in a different coputation time. By default computation time should not 
> differ in range Â± 5 seconds.

4\. Remove the `output` folder with the following command: 
``` bash
rm -f -r output/
```

5\. Then you can just repeat the process from (2.) by runing the script below, specifying the number of cores as an argument. Increase the number initially to 2 CPU and then with increament of 2 (i.e. 4, 6, 8 etc.).


```bash
bash parallel_run.sh <the_number_of_cores>
```

## Structure

The following files are found in this project:

    ðŸ“¦
    â”œâ”€â”€ ðŸ“‚data
    â”‚   â”œâ”€â”€ ðŸ“œvan_de_Schoot_2018.csv
    â”œâ”€â”€ ðŸ“‚output
    â”‚   â”œâ”€â”€ ðŸ“‚simulation
    |   |   â””â”€â”€ ðŸ“‚van_de_Schoot_2018
    |   |       â”œâ”€â”€ ðŸ“‚descriptives
    |   |       |   â”œâ”€â”€ ðŸ“œdata_stats_van_de_Schoot_2018.json
    |   |       |   â”œâ”€â”€ ðŸ“œwordcloud_van_de_Schoot_2018.png
    |   |       |   â”œâ”€â”€ ðŸ“œwordcloud_relevant_van_de_Schoot_2018.png
    |   |       |   â””â”€â”€ ðŸ“œwordcloud_irrelevant_van_de_Schoot_2018.png
    |   |       â”œâ”€â”€ ðŸ“‚state_files
    |   |       |   â”œâ”€â”€ ðŸ“œsim_van_de_Schoot_2018_`x`.asreview
    |   |       |   â””â”€â”€ ðŸ“œ...
    |   |       â”œâ”€â”€ ðŸ“‚metrics
    |   |       â”œ   â”œâ”€â”€ ðŸ“œmetrics_sim_van_de_Schoot_2018_`x`.json
    |   |       |   â””â”€â”€ ðŸ“œ...
    |   |       â””â”€â”€ ðŸ“œplot_recall_van_de_Schoot_2018.png
    â”‚   â””â”€â”€ ðŸ“‚tables
    |       â”œâ”€â”€ ðŸ“œdata_descriptives.csv
    |       â”œâ”€â”€ ðŸ“œdata_descriptives.xlsx
    |       â”œâ”€â”€ ðŸ“œdata_metrics.csv
    |       â””â”€â”€ ðŸ“œdata_metrics.xlsx
    â”œâ”€â”€ ðŸ“‚scripts
    â”‚   â”œâ”€â”€ ðŸ“œget_plot.py
    â”‚   â”œâ”€â”€ ðŸ“œmerge_descriptives.py
    â”‚   â”œâ”€â”€ ðŸ“œmerge_metrics.py
    â”‚   â”œâ”€â”€ ðŸ“œmerge_tds.py
    â”‚   â””â”€â”€ ðŸ“œsplit-file.py
    â”œâ”€â”€ ðŸ“œjobs.sh
    â”œâ”€â”€ ðŸ“œparallel_run.sh
    â””â”€â”€ ðŸ“œREADME.md
